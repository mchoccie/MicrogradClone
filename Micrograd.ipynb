{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "oNVe-kPhOwiM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Value Object.\n",
        "class Value:\n",
        "\n",
        "  def __init__(self, data, _children=(), _op='', label=''):\n",
        "    self.data = data\n",
        "    self.grad = 0.0\n",
        "    self._backward = lambda: None\n",
        "    self._prev = set(_children)\n",
        "    self._op = _op\n",
        "    self.label = label\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Value(data={self.data})\"\n",
        "\n",
        "  def __add__(self, other):\n",
        "    other = other if isinstance(other, Value) else Value(other)\n",
        "    out = Value(self.data + other.data, (self, other), '+')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += 1.0 * out.grad\n",
        "      other.grad += 1.0 * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  def __mul__(self, other):\n",
        "    other = other if isinstance(other, Value) else Value(other)\n",
        "    out = Value(self.data * other.data, (self, other), '*')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += other.data * out.grad\n",
        "      other.grad += self.data * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  def __pow__(self, other):\n",
        "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
        "    out = Value(self.data**other, (self,), f'**{other}')\n",
        "\n",
        "    def _backward():\n",
        "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  def __rmul__(self, other): # other * self\n",
        "    return self * other\n",
        "\n",
        "  def __truediv__(self, other): # self / other\n",
        "    return self * other**-1\n",
        "\n",
        "  def __neg__(self): # -self\n",
        "    return self * -1\n",
        "\n",
        "  def __sub__(self, other): # self - other\n",
        "    return self + (-other)\n",
        "\n",
        "  def __radd__(self, other): # other + self\n",
        "    return self + other\n",
        "\n",
        "  def tanh(self):\n",
        "    #print(type(self))\n",
        "    x = self.data\n",
        "    #print(type(x))\n",
        "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
        "    out = Value(t, (self, ), 'tanh')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += (1 - t**2) * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  def exp(self):\n",
        "    x = self.data\n",
        "    out = Value(math.exp(x), (self, ), 'exp')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "  def backward(self):\n",
        "\n",
        "    topo = []\n",
        "    visited = set()\n",
        "    def build_topo(v):\n",
        "      if v not in visited:\n",
        "        visited.add(v)\n",
        "        for child in v._prev:\n",
        "          build_topo(child)\n",
        "        topo.append(v)\n",
        "    build_topo(self)\n",
        "\n",
        "    self.grad = 1.0\n",
        "    for node in reversed(topo):\n",
        "      node._backward()"
      ],
      "metadata": {
        "id": "cVvjK6oV46Y3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Space to see if the calculations work\n",
        "a = Value(2.0)\n",
        "print(2 * a)"
      ],
      "metadata": {
        "id": "UqAS7V5KO2Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code from Andrej's video to help visualize the connections and the graph network\n",
        "from graphviz import Digraph\n",
        "\n",
        "def trace(root):\n",
        "  # builds a set of all nodes and edges in a graph\n",
        "  nodes, edges = set(), set()\n",
        "  def build(v):\n",
        "    if v not in nodes:\n",
        "      nodes.add(v)\n",
        "      for child in v._prev:\n",
        "        edges.add((child, v))\n",
        "        build(child)\n",
        "  build(root)\n",
        "  return nodes, edges\n",
        "\n",
        "def draw_dot(root):\n",
        "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
        "\n",
        "  nodes, edges = trace(root)\n",
        "  for n in nodes:\n",
        "    uid = str(id(n))\n",
        "    # for any value in the graph, create a rectangular ('record') node for it\n",
        "    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
        "    if n._op:\n",
        "      # if this value is a result of some operation, create an op node for it\n",
        "      dot.node(name = uid + n._op, label = n._op)\n",
        "      # and connect this node to it\n",
        "      dot.edge(uid + n._op, uid)\n",
        "\n",
        "  for n1, n2 in edges:\n",
        "    # connect n1 to the op node of n2\n",
        "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
        "\n",
        "  return dot"
      ],
      "metadata": {
        "id": "yngHhljGLbuq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test to see the graph and it's connections\n",
        "# inputs x1,x2\n",
        "x1 = Value(2.0, label='x1')\n",
        "x2 = Value(0.0, label='x2')\n",
        "# weights w1,w2\n",
        "w1 = Value(-3.0, label='w1')\n",
        "w2 = Value(1.0, label='w2')\n",
        "# bias of the neuron\n",
        "b = Value(6.8813735870195432, label='b')\n",
        "# x1*w1 + x2*w2 + b\n",
        "x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
        "x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
        "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
        "n = x1w1x2w2 + b; n.label = 'n'\n",
        "o = n.tanh()\n",
        "o.label = 'o'\n",
        "o.backward()"
      ],
      "metadata": {
        "id": "DbYIzX07S-UH"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_dot(o)"
      ],
      "metadata": {
        "id": "dr9MwnEeOOiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neuron Class with all the necessary functions for creating an MLP\n",
        "import random\n",
        "class Neuron:\n",
        "  def __init__(self, nin):\n",
        "    self.weights = [Value(random.uniform(-1,1)) for i in range(nin)]\n",
        "    self.bias = Value(random.uniform(-1, 1))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    res = zip(self.weights, x)\n",
        "    total = Value(0)\n",
        "    for i, j in res:\n",
        "      total += j * i\n",
        "    total += self.bias\n",
        "    out = total.tanh()\n",
        "    return out\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.weights + [self.bias]\n",
        "class Layer:\n",
        "  def __init__(self, nin, nouts):\n",
        "    self.neurons = [Neuron(nin) for i in range(nouts)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    outs = [n(x) for n in self.neurons]\n",
        "    return outs[0] if len(outs) == 1 else outs\n",
        "\n",
        "  def parameters(self):\n",
        "    params = []\n",
        "    for n in self.neurons:\n",
        "      params += n.parameters()\n",
        "    return params\n",
        "\n",
        "\n",
        "class MLP:\n",
        "  def __init__(self, nin, nouts):\n",
        "    sz = [nin] + nouts\n",
        "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  def parameters(self):\n",
        "    params = []\n",
        "    for layer in self.layers:\n",
        "      params += layer.parameters()\n",
        "    return params\n",
        "\n",
        "# x = [2.0, 3.0]\n",
        "# node = Neuron(2)\n",
        "# print(node(x))"
      ],
      "metadata": {
        "id": "QhQGrV2Iv3DL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [2.0, 3.0, -1.0]\n",
        "n = MLP(784, [3, 3, 1])"
      ],
      "metadata": {
        "id": "L98fxcsSIhId"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Small test data set that Andrej created in his video\n",
        "xs = [[2.0, 3.0, -1.0],\n",
        "      [3.0, -1.0, 5.0],\n",
        "      [0.5, 1.0, -2.0],\n",
        "      [1.0, 1.0, -1.0]]\n",
        "\n",
        "ys = [1.0, -1.0, -1.0, 1.0]"
      ],
      "metadata": {
        "id": "kV_RIxvjMK7F"
      },
      "execution_count": 969,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entire forward and backward pass process\n",
        "for k in range(50):\n",
        "  ypred = [n(x) for x in xs]\n",
        "  loss = sum((act-pred)**2 for act, pred in zip(ypred, ys))\n",
        "  loss.backward()\n",
        "  for p in n.parameters():\n",
        "    p.data += -0.01 * p.grad\n",
        "  print(k, loss)\n",
        "  print(ypred)\n",
        "  break\n"
      ],
      "metadata": {
        "id": "5lkSN9kOor5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST CODE\n",
        "This process still isn't entirely a 100 percent. The values encounter overflow exceptions sometimes which I still need to fix, but here is my progress thus far."
      ],
      "metadata": {
        "id": "vtOHWKN2PXCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in MNIST data\n",
        "import csv\n",
        "labels = []\n",
        "train_set = []\n",
        "with open('mnist_train.csv', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        vals = list(row.values())\n",
        "        label = vals.pop(0)\n",
        "        labels.append(int(label))\n",
        "\n",
        "        train_set.append([int(i) for i in vals])\n",
        "print(len(train_set[0]))"
      ],
      "metadata": {
        "id": "BRlcOqo0NK_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward and backward pass process for the MNIST data\n",
        "for k in range(50):\n",
        "  ypred = [n(x) for x in training]\n",
        "  loss = sum((act-pred)**2 for act, pred in zip(ypred, labels))\n",
        "  loss.backward()\n",
        "  for p in n.parameters():\n",
        "   p.data += -0.05 * p.grad\n",
        "  print(k, loss)\n",
        "  print(ypred)\n",
        ""
      ],
      "metadata": {
        "id": "PATDJgnkTuvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform scaling on the data\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_scaler2 = preprocessing.MinMaxScaler()\n",
        "train_set = min_max_scaler.fit_transform(train_set)\n",
        "labels = min_max_scaler2.fit_transform(labels)"
      ],
      "metadata": {
        "id": "s2k728FyrBPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempted to reduce data size because too much RAM was being utilized\n",
        "training = train_set[0:100]\n",
        "print(len(training))\n",
        "labels = labels[0:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZC6RptergPo",
        "outputId": "7b650220-f39c-4ffd-9fbf-8a37fa19ed15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    }
  ]
}